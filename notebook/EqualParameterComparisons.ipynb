{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Comparison with classical models\n","\n","In this notebook we provide a comparison between the hybrid network and some well-known classical CNNs. \n","The considered classical models are:\n","\n","1. ResNet50\n","2. DenseNet169\n","3. VGG-19\n","4. EfficientNet\n","5. Inception\n","\n"],"metadata":{"id":"c6AwvsI5AU5I"}},{"cell_type":"markdown","source":["Import all the necessary libraries"],"metadata":{"id":"FkX5-L8FBvPK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"EbpJc_Uo_r6p"},"outputs":[],"source":["import os\n","import numpy as np\n","import torch\n","import torch.utils.data as data\n","from torch.utils.data import DataLoader\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","from torchvision import datasets, models, transforms\n","\n","import glob\n","import random\n","import numpy as np\n","import argparse\n","\n","from PIL import Image\n","from google.colab import drive\n","import zipfile\n","\n","np.random.seed = 12\n","torch.manual_seed(12)\n","random.seed(12)"]},{"cell_type":"markdown","source":["Mounting data-set files from Google Drive. \n","\n","For more information see the instruction in [QuantumProjectBinucci.ipynb](https://colab.research.google.com/drive/1Yoh6_thHPRiti2YuuZqGIBGLyr2UKjqP?usp=sharing)"],"metadata":{"id":"08et389NB6Nv"}},{"cell_type":"code","source":["drive.mount('/content/gdrive')\n","zip_ref = zipfile.ZipFile(\"/content/gdrive/MyDrive/Progetto Quantum Binucci PhD/Data/archive.zip\", 'r')\n","zip_ref.extractall(\"/content/dataset\")\n","zip_ref.close()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d7eSzKFwB5wf","executionInfo":{"status":"ok","timestamp":1677660568654,"user_tz":-60,"elapsed":10438,"user":{"displayName":"Andrea Ceschini","userId":"09610875268120066951"}},"outputId":"af124b61-8c56-4bb4-9c7c-8865e30e0af7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["**Dataset** class, used in order to manage the dataset loading. "],"metadata":{"id":"bNDTPG79CX7R"}},{"cell_type":"code","source":["class Dataset(data.Dataset):\n","    # mapping table of label and index\n","\n","\n","    def __init__(self, train, **kwargs):\n","        super(Dataset, self).__init__()\n","\n","        self.str2label = {\"buildings\": 0, \"forest\": 1, \"glacier\": 2, \"mountain\": 3, \"sea\": 4, \"street\": 5}\n","        self.label2str = {0: \"buildings\", 1: \"forest\", 2: \"glacier\", 3: \"mountain\", 4: \"sea\", 5: \"street\"}\n","\n","        self.data = list()\n","        self.size = kwargs.get(\"size\", None)\n","        self.data_root = kwargs.get(\"data_root\", \"./Data\")\n","        # self.data_root = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'data')\n","\n","        # load csv file and import file paths\n","        main_dir = \"seg_train\" if train else \"seg_test\"\n","        print(os.path.join(self.data_root, main_dir))\n","\n","        for current_dir in os.listdir(os.path.join(self.data_root,main_dir)):\n","            for current_file in os.listdir(os.path.join(self.data_root,main_dir,current_dir)):\n","                path = os.path.join(self.data_root,main_dir,current_dir,current_file)\n","                self.data.append((path,current_dir))\n","\n","        self.transform = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","        ])\n","\n","    def __getitem__(self, index):\n","        path, label = self.data[index]\n","        image = Image.open(path)\n","\n","        # resize input images\n","        if self.size:\n","            image = image.resize((self.size, self.size), Image.BICUBIC)\n","\n","        label = self.str2label[label]\n","\n","        return self.transform(image), label\n","\n","    def __len__(self):\n","        return len(self.data)"],"metadata":{"id":"cOTTAPN_CQxX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Solver** class, used in order to manage the train/evaluation process"],"metadata":{"id":"pQipphdwCk-w"}},{"cell_type":"code","source":["class Solver():\n","    def __init__(self, args,**kwargs):\n","        # prepare a dataset\n","        self.train_data = Dataset(train=True,\n","                                  data_root=args.data_root,\n","                                  size=args.image_size)\n","\n","\n","        self.test_data = Dataset(train=False,\n","                                 data_root=args.data_root,\n","                                 size=args.image_size)\n","        \n","        #Splitting the data-set in training/validation. For reproducibility purposes we consider fixed\n","        #seed (42).\n","        lengths = [int(0.2*len(self.train_data)), len(self.train_data) - int(0.2 * len(self.train_data))]\n","        self.train_set, self.val_set = torch.utils.data.random_split(self.train_data,\n","                                                           lengths,\n","                                                           torch.Generator().manual_seed(42))\n","\n","        self.train_loader = DataLoader(dataset=self.train_set,\n","                                       batch_size=args.batch_size,\n","                                       shuffle=True, drop_last=True)\n","        \n","        self.test_loader = DataLoader(dataset=self.test_data,\n","                                       batch_size=args.batch_size,\n","                                       shuffle=True, drop_last=True)\n","\n","        # turn on the CUDA if available\n","        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","        print(f'Current device: {self.device}')\n","        ########################################################################\n","        #Loading network to train/test. By default, the script load the pre-trained ResNet50\n","        self.net = kwargs.get('net',models.resnet50(pretrained=True)).to(self.device)\n","        print(f'You requested the training of: {self.net.__class__.__name__}')\n","        ########################################################################\n","\n","\n","        self.loss_fn = torch.nn.CrossEntropyLoss()\n","        self.optim = torch.optim.Adam(self.net.parameters(), lr=args.lr)\n","        self.args = args\n","\n","        if not os.path.exists(args.ckpt_dir):\n","            os.makedirs(args.ckpt_dir)\n","\n","    def fit(self):\n","        max_accuracy = 0\n","      \n","        args = self.args\n","        for epoch in range(args.max_epochs):\n","            self.net.train()\n","            for step, inputs in enumerate(self.train_loader):\n","\n","                \n","                images = inputs[0].to(self.device)\n","                labels = inputs[1].to(self.device)\n","                pred = self.net(images)\n","                loss = self.loss_fn(pred, labels)\n","\n","                self.optim.zero_grad()\n","                loss.backward()\n","                self.optim.step()\n","                if (step+1) % args.print_every_minibatches==0:\n","                  print(\"Epoch [{}/{}] Batch [{}/{}] Loss: {:.3f}\".\n","                      format(epoch + 1, args.max_epochs,step+1, len(self.train_loader), loss.item()))\n","            if (epoch + 1) % args.print_every == 0:\n","                train_acc = self.evaluate(self.train_data)\n","                test_acc = self.evaluate(self.val_set)\n","\n","                print(\"Epoch [{}/{}] Loss: {:.3f} Train Acc: {:.3f}, Test Acc: {:.3f}\".\n","                      format(epoch + 1, args.max_epochs, loss.item(), train_acc, test_acc))\n","                if test_acc > max_accuracy:\n","                  max_accuracy = test_acc\n","                  self.save(args.ckpt_dir, args.ckpt_name, 'best')\n","\n","    def evaluate(self, data):\n","        args = self.args\n","        loader = DataLoader(data,\n","                            batch_size=args.batch_size,\n","                            shuffle=False)\n","\n","        self.net.eval()\n","        num_correct, num_total = 0, 0\n","\n","        with torch.no_grad():\n","            for inputs in loader:\n","                images = inputs[0].to(self.device)\n","                labels = inputs[1].to(self.device)\n","\n","                outputs = self.net(images)\n","                _, preds = torch.max(outputs.detach(), 1)\n","\n","                num_correct += (preds == labels).sum().item()\n","                num_total += labels.size(0)\n","\n","        return num_correct / num_total\n","\n","    def test(self):\n","      return self.evaluate(self.test_data)\n","\n","    def load_network(self,net):\n","      self.net = net\n","\n","\n","\n","    def save(self, ckpt_dir, ckpt_name, global_step):\n","        save_path = os.path.join(\n","            ckpt_dir, \"{}_{}.pth\".format(ckpt_name, global_step))\n","        torch.save(self.net.state_dict(), save_path)"],"metadata":{"id":"o4bVTRTiCsbn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prepare_network_for_t_learning(net,**kwargs):\n","    freeze_parameters = kwargs.get('freeze_parameters',True)\n","    in_j_layer = kwargs.get('in_j_layer',4)\n","    out_j_layer = kwargs.get('out_j_layer',3)\n","    if freeze_parameters == True:\n","      for param in net.parameters():\n","          param.requires_grad = False\n","    net_name = net.__class__.__name__\n","    if net_name=='DenseNet':\n","      #Getting the number of output classes\n","      output_classes = kwargs.get('output_classes',6)\n","      num_ftrs = net.classifier.in_features\n","\n","      junc_layer_1 = nn.Linear(num_ftrs,in_j_layer)\n","      fc_intermediate_layer = nn.Linear(in_j_layer,out_j_layer)\n","      junc_layer_2 = nn.Linear(out_j_layer,output_classes)\n","\n","      #Adapating the last layer of the network to the specific classification task\n","      net.classifier = nn.Sequential(junc_layer_1,fc_intermediate_layer,junc_layer_2)\n","    elif net_name == 'ResNet':\n","      #Getting the number of output classes\n","      output_classes = kwargs.get('output_classes',6)\n","      num_ftrs = net.fc.in_features\n","\n","      junc_layer_1 = nn.Linear(num_ftrs,in_j_layer)\n","      fc_intermediate_layer = nn.Linear(in_j_layer,out_j_layer)\n","      junc_layer_2 = nn.Linear(out_j_layer,output_classes)\n","\n","      #Adapating the last layer of the network to the specific classification task\n","      net.fc = nn.Sequential(junc_layer_1,fc_intermediate_layer,junc_layer_2)\n","    elif net_name == 'VGG':\n","      output_classes = kwargs.get('output_classes',6)\n","      num_ftrs = net.classifier[6].in_features\n","\n","      junc_layer_1 = nn.Linear(num_ftrs,in_j_layer)\n","      fc_intermediate_layer = nn.Linear(in_j_layer,out_j_layer)\n","      junc_layer_2 = nn.Linear(out_j_layer,output_classes)\n","\n","      net.classifier[6] = nn.Sequential(junc_layer_1,fc_intermediate_layer,junc_layer_2)\n","    elif net_name == 'EfficientNet':\n","      output_classes = kwargs.get('output_classes',6)\n","      num_ftrs = net.classifier.fc.in_features\n","      #Adapating the last layer of the network to the specific classification task\n","\n","      junc_layer_1 = nn.Linear(num_ftrs,in_j_layer)\n","      fc_intermediate_layer = nn.Linear(in_j_layer,out_j_layer)\n","      junc_layer_2 = nn.Linear(out_j_layer,output_classes)\n","\n","      net.classifier.fc = nn.Sequential(junc_layer_1,fc_intermediate_layer,junc_layer_2)\n","    elif net_name == \"Inception3\":\n","      output_classes = kwargs.get('output_classes',6)\n","      num_ftrs = net.fc.in_features\n","      #Adapating the last layer of the network to the specific classification task\n","\n","      junc_layer_1 = nn.Linear(num_ftrs,in_j_layer)\n","      fc_intermediate_layer = nn.Linear(in_j_layer,out_j_layer)\n","      junc_layer_2 = nn.Linear(out_j_layer,output_classes)\n","\n","      net.fc = nn.Sequential(junc_layer_1,fc_intermediate_layer,junc_layer_2)\n","      net.aux_logits=False\n","    num_params = 0\n","    num_params += sum(param.numel() for param in net.parameters() if param.requires_grad)\n","    print('You requested the train of: ',net_name)\n","    print('Number of parameters:',num_params)\n","    return net"],"metadata":{"id":"yvcmnchYgKL-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Train class, used in order to perform the training process."],"metadata":{"id":"b8aqYyQUD8v_"}},{"cell_type":"code","source":["def main():\n","    parser = argparse.ArgumentParser()\n","    \n","    model_set = {'ResNet50': models.resnet50(pretrained=True), \n","                 'DenseNet169': models.densenet169(pretrained=True), \n","                 'VGG19': models.vgg19(pretrained=True),\n","                 'EfficientNet': torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0',\n","                                                pretrained=True),\n","                 'Inception': torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)}\n","\n","    parser.add_argument(\"--model_to_test\",type=str,default='Inception')\n","    parser.add_argument(\"--test\",type=bool,default=False)\n","    parser.add_argument(\"--lr\", type=float, default=1e-3)\n","    parser.add_argument(\"--batch_size\", type=int, default=64)\n","    parser.add_argument(\"--max_epochs\", type=int, default=30)\n","\n","    parser.add_argument(\"--ckpt_dir\", type=str, default=\"/content/gdrive/MyDrive/Progetto Quantum Binucci PhD/CheckpointSmallParametersNumber/VGG19/seed12\")\n","    parser.add_argument(\"--path_to_test\",type=str,default=\"/content/gdrive/MyDrive/Progetto Quantum Binucci PhD/CheckpointSmallParametersNumber/VGG19/seed12/landscape_best.pth\")\n","    parser.add_argument(\"--ckpt_name\", type=str, default=\"landscape\")\n","    parser.add_argument(\"--print_every\", type=int, default=1)\n","    parser.add_argument(\"--print_every_minibatches\", type=int, default=10)\n","\n","    # if you change image size, you must change all the network channels\n","    parser.add_argument(\"--image_size\", type=int, default=299)\n","    parser.add_argument(\"--data_root\", type=str, default=\"/content/dataset\")\n","\n","\n","\n","    args, unknown = parser.parse_known_args()\n","\n","    net = prepare_network_for_t_learning(model_set[args.model_to_test],freeze_parameters = True)\n","\n","    print(\"Test mode\" if args.test else \"Train Mode\")\n","\n","    solver = Solver(args,net=net)\n","    \n","    if args.test==False:\n","      solver.fit()\n","    else:\n","      net.load_state_dict(torch.load(args.path_to_test,map_location=torch.device('cpu')))\n","      solver.load_network(net)\n","      accuracy = solver.test()\n","      print(f'Accuracy on the test-set for {net.__class__.__name__} = {accuracy*100}%')\n","      \n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"XPal7ereD9Cu","colab":{"base_uri":"https://localhost:8080/"},"outputId":"57764d04-c1d7-46d1-dd77-d06c5374deeb"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"output_type":"stream","name":"stdout","text":["You requested the train of:  VGG\n","Number of parameters: 16427\n","Train Mode\n","/content/dataset/seg_train\n","/content/dataset/seg_test\n","Current device: cuda\n","You requested the training of: VGG\n","Epoch [1/30] Batch [10/43] Loss: 1.475\n","Epoch [1/30] Batch [20/43] Loss: 1.267\n","Epoch [1/30] Batch [30/43] Loss: 1.298\n","Epoch [1/30] Batch [40/43] Loss: 1.142\n","Epoch [1/30] Loss: 1.040 Train Acc: 0.526, Test Acc: 0.527\n","Epoch [2/30] Batch [10/43] Loss: 0.894\n","Epoch [2/30] Batch [20/43] Loss: 0.872\n","Epoch [2/30] Batch [30/43] Loss: 0.916\n","Epoch [2/30] Batch [40/43] Loss: 0.889\n","Epoch [2/30] Loss: 0.705 Train Acc: 0.713, Test Acc: 0.715\n","Epoch [3/30] Batch [10/43] Loss: 0.719\n","Epoch [3/30] Batch [20/43] Loss: 0.719\n","Epoch [3/30] Batch [30/43] Loss: 0.553\n","Epoch [3/30] Batch [40/43] Loss: 0.785\n","Epoch [3/30] Loss: 0.652 Train Acc: 0.717, Test Acc: 0.721\n","Epoch [4/30] Batch [10/43] Loss: 0.609\n","Epoch [4/30] Batch [20/43] Loss: 0.585\n","Epoch [4/30] Batch [30/43] Loss: 0.636\n","Epoch [4/30] Batch [40/43] Loss: 0.730\n","Epoch [4/30] Loss: 0.590 Train Acc: 0.833, Test Acc: 0.835\n","Epoch [5/30] Batch [10/43] Loss: 0.532\n","Epoch [5/30] Batch [20/43] Loss: 0.575\n","Epoch [5/30] Batch [30/43] Loss: 0.632\n","Epoch [5/30] Batch [40/43] Loss: 0.353\n","Epoch [5/30] Loss: 0.524 Train Acc: 0.868, Test Acc: 0.868\n","Epoch [6/30] Batch [10/43] Loss: 0.481\n","Epoch [6/30] Batch [20/43] Loss: 0.492\n","Epoch [6/30] Batch [30/43] Loss: 0.456\n","Epoch [6/30] Batch [40/43] Loss: 0.555\n","Epoch [6/30] Loss: 0.335 Train Acc: 0.882, Test Acc: 0.882\n","Epoch [7/30] Batch [10/43] Loss: 0.254\n","Epoch [7/30] Batch [20/43] Loss: 0.417\n","Epoch [7/30] Batch [30/43] Loss: 0.454\n","Epoch [7/30] Batch [40/43] Loss: 0.248\n","Epoch [7/30] Loss: 0.382 Train Acc: 0.888, Test Acc: 0.888\n","Epoch [8/30] Batch [10/43] Loss: 0.283\n","Epoch [8/30] Batch [20/43] Loss: 0.470\n","Epoch [8/30] Batch [30/43] Loss: 0.307\n","Epoch [8/30] Batch [40/43] Loss: 0.250\n","Epoch [8/30] Loss: 0.386 Train Acc: 0.891, Test Acc: 0.889\n","Epoch [9/30] Batch [10/43] Loss: 0.332\n","Epoch [9/30] Batch [20/43] Loss: 0.328\n","Epoch [9/30] Batch [30/43] Loss: 0.298\n","Epoch [9/30] Batch [40/43] Loss: 0.260\n","Epoch [9/30] Loss: 0.313 Train Acc: 0.893, Test Acc: 0.891\n","Epoch [10/30] Batch [10/43] Loss: 0.462\n","Epoch [10/30] Batch [20/43] Loss: 0.393\n","Epoch [10/30] Batch [30/43] Loss: 0.200\n","Epoch [10/30] Batch [40/43] Loss: 0.274\n","Epoch [10/30] Loss: 0.272 Train Acc: 0.895, Test Acc: 0.892\n","Epoch [11/30] Batch [10/43] Loss: 0.390\n","Epoch [11/30] Batch [20/43] Loss: 0.306\n","Epoch [11/30] Batch [30/43] Loss: 0.453\n","Epoch [11/30] Batch [40/43] Loss: 0.245\n","Epoch [11/30] Loss: 0.241 Train Acc: 0.898, Test Acc: 0.895\n","Epoch [12/30] Batch [10/43] Loss: 0.326\n","Epoch [12/30] Batch [20/43] Loss: 0.303\n","Epoch [12/30] Batch [30/43] Loss: 0.496\n","Epoch [12/30] Batch [40/43] Loss: 0.433\n","Epoch [12/30] Loss: 0.232 Train Acc: 0.901, Test Acc: 0.898\n","Epoch [13/30] Batch [10/43] Loss: 0.176\n","Epoch [13/30] Batch [20/43] Loss: 0.234\n","Epoch [13/30] Batch [30/43] Loss: 0.235\n","Epoch [13/30] Batch [40/43] Loss: 0.352\n","Epoch [13/30] Loss: 0.551 Train Acc: 0.904, Test Acc: 0.900\n","Epoch [14/30] Batch [10/43] Loss: 0.289\n","Epoch [14/30] Batch [20/43] Loss: 0.264\n","Epoch [14/30] Batch [30/43] Loss: 0.293\n","Epoch [14/30] Batch [40/43] Loss: 0.349\n","Epoch [14/30] Loss: 0.173 Train Acc: 0.901, Test Acc: 0.898\n","Epoch [15/30] Batch [10/43] Loss: 0.350\n","Epoch [15/30] Batch [20/43] Loss: 0.288\n","Epoch [15/30] Batch [30/43] Loss: 0.299\n","Epoch [15/30] Batch [40/43] Loss: 0.213\n","Epoch [15/30] Loss: 0.394 Train Acc: 0.905, Test Acc: 0.902\n","Epoch [16/30] Batch [10/43] Loss: 0.306\n","Epoch [16/30] Batch [20/43] Loss: 0.544\n","Epoch [16/30] Batch [30/43] Loss: 0.213\n","Epoch [16/30] Batch [40/43] Loss: 0.246\n","Epoch [16/30] Loss: 0.272 Train Acc: 0.908, Test Acc: 0.903\n","Epoch [17/30] Batch [10/43] Loss: 0.304\n","Epoch [17/30] Batch [20/43] Loss: 0.242\n","Epoch [17/30] Batch [30/43] Loss: 0.508\n","Epoch [17/30] Batch [40/43] Loss: 0.122\n","Epoch [17/30] Loss: 0.298 Train Acc: 0.908, Test Acc: 0.903\n","Epoch [18/30] Batch [10/43] Loss: 0.141\n","Epoch [18/30] Batch [20/43] Loss: 0.209\n","Epoch [18/30] Batch [30/43] Loss: 0.283\n","Epoch [18/30] Batch [40/43] Loss: 0.304\n","Epoch [18/30] Loss: 0.135 Train Acc: 0.909, Test Acc: 0.903\n","Epoch [19/30] Batch [10/43] Loss: 0.218\n","Epoch [19/30] Batch [20/43] Loss: 0.281\n","Epoch [19/30] Batch [30/43] Loss: 0.250\n","Epoch [19/30] Batch [40/43] Loss: 0.311\n","Epoch [19/30] Loss: 0.174 Train Acc: 0.911, Test Acc: 0.905\n","Epoch [20/30] Batch [10/43] Loss: 0.248\n","Epoch [20/30] Batch [20/43] Loss: 0.206\n","Epoch [20/30] Batch [30/43] Loss: 0.224\n","Epoch [20/30] Batch [40/43] Loss: 0.241\n","Epoch [20/30] Loss: 0.265 Train Acc: 0.909, Test Acc: 0.903\n","Epoch [21/30] Batch [10/43] Loss: 0.409\n","Epoch [21/30] Batch [20/43] Loss: 0.168\n","Epoch [21/30] Batch [30/43] Loss: 0.182\n","Epoch [21/30] Batch [40/43] Loss: 0.272\n","Epoch [21/30] Loss: 0.432 Train Acc: 0.912, Test Acc: 0.907\n","Epoch [22/30] Batch [10/43] Loss: 0.180\n","Epoch [22/30] Batch [20/43] Loss: 0.185\n","Epoch [22/30] Batch [30/43] Loss: 0.215\n","Epoch [22/30] Batch [40/43] Loss: 0.301\n","Epoch [22/30] Loss: 0.189 Train Acc: 0.912, Test Acc: 0.905\n","Epoch [23/30] Batch [10/43] Loss: 0.250\n","Epoch [23/30] Batch [20/43] Loss: 0.156\n","Epoch [23/30] Batch [30/43] Loss: 0.321\n","Epoch [23/30] Batch [40/43] Loss: 0.227\n","Epoch [23/30] Loss: 0.469 Train Acc: 0.910, Test Acc: 0.902\n","Epoch [24/30] Batch [10/43] Loss: 0.231\n","Epoch [24/30] Batch [20/43] Loss: 0.154\n","Epoch [24/30] Batch [30/43] Loss: 0.343\n","Epoch [24/30] Batch [40/43] Loss: 0.228\n","Epoch [24/30] Loss: 0.269 Train Acc: 0.908, Test Acc: 0.902\n","Epoch [25/30] Batch [10/43] Loss: 0.388\n","Epoch [25/30] Batch [20/43] Loss: 0.455\n","Epoch [25/30] Batch [30/43] Loss: 0.202\n","Epoch [25/30] Batch [40/43] Loss: 0.162\n","Epoch [25/30] Loss: 0.322 Train Acc: 0.912, Test Acc: 0.906\n","Epoch [26/30] Batch [10/43] Loss: 0.192\n","Epoch [26/30] Batch [20/43] Loss: 0.218\n","Epoch [26/30] Batch [30/43] Loss: 0.230\n","Epoch [26/30] Batch [40/43] Loss: 0.253\n","Epoch [26/30] Loss: 0.234 Train Acc: 0.911, Test Acc: 0.904\n","Epoch [27/30] Batch [10/43] Loss: 0.135\n","Epoch [27/30] Batch [20/43] Loss: 0.202\n","Epoch [27/30] Batch [30/43] Loss: 0.222\n","Epoch [27/30] Batch [40/43] Loss: 0.280\n","Epoch [27/30] Loss: 0.210 Train Acc: 0.916, Test Acc: 0.908\n","Epoch [28/30] Batch [10/43] Loss: 0.250\n","Epoch [28/30] Batch [20/43] Loss: 0.213\n","Epoch [28/30] Batch [30/43] Loss: 0.265\n","Epoch [28/30] Batch [40/43] Loss: 0.346\n","Epoch [28/30] Loss: 0.166 Train Acc: 0.915, Test Acc: 0.907\n","Epoch [29/30] Batch [10/43] Loss: 0.192\n","Epoch [29/30] Batch [20/43] Loss: 0.292\n","Epoch [29/30] Batch [30/43] Loss: 0.172\n","Epoch [29/30] Batch [40/43] Loss: 0.296\n"]}]}]}