{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Comparison with classical models\n","\n","In this notebook we provide a comparison between the hybrid network and some well-known classical CNNs. \n","The considered classical models are:\n","\n","1. ResNet50\n","2. DenseNet169\n","3. VGG-19\n","4. MobileNet\n","\n"],"metadata":{"id":"c6AwvsI5AU5I"}},{"cell_type":"markdown","source":["Import all the necessary libraries"],"metadata":{"id":"FkX5-L8FBvPK"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"EbpJc_Uo_r6p","executionInfo":{"status":"ok","timestamp":1685349494678,"user_tz":-120,"elapsed":693,"user":{"displayName":"Alessio Verdone","userId":"05192661317951122010"}}},"outputs":[],"source":["import os\n","import numpy as np\n","import torch\n","import torch.utils.data as data\n","from torch.utils.data import DataLoader\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","from torchvision import datasets, models, transforms\n","\n","import glob\n","import random\n","import numpy as np\n","import argparse\n","\n","from PIL import Image\n","from google.colab import drive\n","import zipfile"]},{"cell_type":"markdown","source":["Mounting data-set files from Google Drive. \n","\n","For more information see the instruction in [QuantumProjectBinucci.ipynb](https://colab.research.google.com/drive/1Yoh6_thHPRiti2YuuZqGIBGLyr2UKjqP?usp=sharing)"],"metadata":{"id":"08et389NB6Nv"}},{"cell_type":"code","source":["drive.mount('/content/gdrive')\n","# le immagini sono gi√† estratte in \"/content/gdrive/MyDrive/Progetto Quantum Binucci PhD/Data\"\n","# zip_ref = zipfile.ZipFile(\"/content/gdrive/MyDrive/Progetto Quantum Binucci PhD/Data/archive.zip\", 'r')\n","# zip_ref.extractall(\"/content/dataset\")\n","# zip_ref.close()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d7eSzKFwB5wf","executionInfo":{"status":"ok","timestamp":1685349491505,"user_tz":-120,"elapsed":2871,"user":{"displayName":"Alessio Verdone","userId":"05192661317951122010"}},"outputId":"87e984a5-4957-4590-897e-b52983b562c4"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["**Dataset** class, used in order to manage the dataset loading. "],"metadata":{"id":"bNDTPG79CX7R"}},{"cell_type":"code","source":["class Dataset(data.Dataset):\n","    # mapping table of label and index\n","\n","\n","    def __init__(self, train, **kwargs):\n","        super(Dataset, self).__init__()\n","\n","        self.str2label = {\"buildings\": 0, \"forest\": 1, \"glacier\": 2, \"mountain\": 3, \"sea\": 4, \"street\": 5}\n","        self.label2str = {0: \"buildings\", 1: \"forest\", 2: \"glacier\", 3: \"mountain\", 4: \"sea\", 5: \"street\"}\n","\n","        self.data = list()\n","        self.size = kwargs.get(\"size\", None)\n","        self.data_root = kwargs.get(\"data_root\", \"./Data\")\n","        # self.data_root = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'data')\n","\n","        # load csv file and import file paths\n","        main_dir = \"seg_train\" if train else \"seg_test\"\n","        print(os.path.join(self.data_root, main_dir))\n","\n","        for current_dir in os.listdir(os.path.join(self.data_root,main_dir)):\n","            for current_file in os.listdir(os.path.join(self.data_root,main_dir,current_dir)):\n","                path = os.path.join(self.data_root,main_dir,current_dir,current_file)\n","                self.data.append((path,current_dir))\n","\n","        self.transform = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","        ])\n","\n","    def __getitem__(self, index):\n","        path, label = self.data[index]\n","        image = Image.open(path)\n","\n","        # resize input images\n","        if self.size:\n","            image = image.resize((self.size, self.size), Image.BICUBIC)\n","\n","        label = self.str2label[label]\n","\n","        return self.transform(image), label\n","\n","    def __len__(self):\n","        return len(self.data)"],"metadata":{"id":"cOTTAPN_CQxX","executionInfo":{"status":"ok","timestamp":1685349496985,"user_tz":-120,"elapsed":6,"user":{"displayName":"Alessio Verdone","userId":"05192661317951122010"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["**Solver** class, used in order to manage the train/evaluation process"],"metadata":{"id":"pQipphdwCk-w"}},{"cell_type":"code","source":["class Solver():\n","    def __init__(self, args,**kwargs):\n","        # prepare a dataset\n","        self.train_data = Dataset(train=True,\n","                                  data_root=args.data_root,\n","                                  size=args.image_size)\n","\n","\n","        self.test_data = Dataset(train=False,\n","                                 data_root=args.data_root,\n","                                 size=args.image_size)\n","        \n","        #Splitting the data-set in training/validation. For reproducibility purposes we consider fixed\n","        #seed (42).\n","        lengths = [int(0.8*len(self.train_data)), len(self.train_data) - int(0.8 * len(self.train_data))]\n","        self.train_set, self.val_set = torch.utils.data.random_split(self.train_data,\n","                                                           lengths,\n","                                                           torch.Generator().manual_seed(42))\n","\n","        self.train_loader = DataLoader(dataset=self.train_set,\n","                                       batch_size=args.batch_size,\n","                                       num_workers=4,\n","                                       shuffle=True, drop_last=True)\n","        \n","        self.test_loader = DataLoader(dataset=self.test_data,\n","                                       batch_size=args.batch_size,\n","                                       num_workers=4,\n","                                       shuffle=True, drop_last=True)\n","\n","        # turn on the CUDA if available\n","        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","        print(f'Current device: {self.device}')\n","        ########################################################################\n","        #Loading network to train/test. By default, the script load the pre-trained ResNet50\n","        self.net = kwargs.get('net',models.resnet50(pretrained=True)).to(self.device)\n","        print(f'You requested the training of: {self.net.__class__.__name__}')\n","        ########################################################################\n","\n","\n","        self.loss_fn = torch.nn.CrossEntropyLoss()\n","        self.optim = torch.optim.Adam(self.net.parameters(), lr=args.lr)\n","        self.args = args\n","\n","        if not os.path.exists(args.ckpt_dir):\n","            os.makedirs(args.ckpt_dir)\n","\n","    def fit(self):\n","\n","      \n","        args = self.args\n","        for epoch in range(args.max_epochs):\n","            self.net.train()\n","            for step, inputs in enumerate(self.train_loader):\n","\n","                \n","                images = inputs[0].to(self.device)\n","                labels = inputs[1].to(self.device)\n","                pred = self.net(images)\n","                loss = self.loss_fn(pred, labels)\n","\n","                self.optim.zero_grad()\n","                loss.backward()\n","                self.optim.step()\n","                if (step+1) % args.print_every_minibatches==0:\n","                  print(\"Epoch [{}/{}] Batch [{}/{}] Loss: {:.3f}\".\n","                      format(epoch + 1, args.max_epochs,step+1, len(self.train_loader), loss.item()))\n","            if (epoch + 1) % args.print_every == 0:\n","                train_acc = self.evaluate(self.train_data)\n","                test_acc = self.evaluate(self.val_set)\n","\n","                print(\"Epoch [{}/{}] Loss: {:.3f} Train Acc: {:.3f}, Test Acc: {:.3f}\".\n","                      format(epoch + 1, args.max_epochs, loss.item(), train_acc, test_acc))\n","\n","                self.save(args.ckpt_dir, args.ckpt_name, epoch + 1)\n","\n","    def evaluate(self, data):\n","        args = self.args\n","        loader = DataLoader(data,\n","                            batch_size=args.batch_size,\n","                            num_workers=1,\n","                            shuffle=False)\n","\n","        self.net.eval()\n","        num_correct, num_total = 0, 0\n","\n","        with torch.no_grad():\n","            for inputs in loader:\n","                images = inputs[0].to(self.device)\n","                labels = inputs[1].to(self.device)\n","\n","                outputs = self.net(images)\n","                _, preds = torch.max(outputs.detach(), 1)\n","\n","                num_correct += (preds == labels).sum().item()\n","                num_total += labels.size(0)\n","\n","        return num_correct / num_total\n","\n","    def test(self):\n","      return self.evaluate(self.test_data)\n","\n","    def load_network(self,net):\n","      self.net = net\n","\n","\n","\n","    def save(self, ckpt_dir, ckpt_name, global_step):\n","        save_path = os.path.join(\n","            ckpt_dir, \"{}_{}.pth\".format(ckpt_name, global_step))\n","        torch.save(self.net.state_dict(), save_path)"],"metadata":{"id":"o4bVTRTiCsbn","executionInfo":{"status":"ok","timestamp":1685349499298,"user_tz":-120,"elapsed":1,"user":{"displayName":"Alessio Verdone","userId":"05192661317951122010"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def prepare_network_for_t_learning(net,**kwargs):\n","  net_name = net.__class__.__name__\n","  if net_name=='DenseNet':\n","    #Getting the number of output classes\n","    output_classes = kwargs.get('output_classes',6)\n","    num_ftrs = net.classifier.in_features\n","    #Adapating the last layer of the network to the specific classification task\n","    net.classifier = nn.Linear(num_ftrs, output_classes)\n","  elif net_name == 'ResNet':\n","    #Getting the number of output classes\n","    output_classes = kwargs.get('output_classes',6)\n","    num_ftrs = net.fc.in_features\n","    #Adapating the last layer of the network to the specific classification task\n","    net.fc = nn.Linear(num_ftrs, output_classes)\n","  elif net_name == 'VGG':\n","    output_classes = kwargs.get('output_classes',6)\n","    num_ftrs = net.classifier[6].in_features\n","    net.classifier[6] = nn.Linear(num_ftrs,output_classes)\n","  elif net_name == 'EfficientNet':\n","    output_classes = kwargs.get('output_classes',6)\n","    num_ftrs = net.classifier.fc.in_features\n","    #Adapating the last layer of the network to the specific classification task\n","    net.classifier.fc = nn.Linear(num_ftrs, output_classes)\n","  num_params = 0\n","  num_params += sum(param.numel() for param in net.parameters() if param.requires_grad)\n","  print('Number of parameters:',num_params)\n","  return net\n","\n","\n"],"metadata":{"id":"yvcmnchYgKL-","executionInfo":{"status":"ok","timestamp":1685349502119,"user_tz":-120,"elapsed":239,"user":{"displayName":"Alessio Verdone","userId":"05192661317951122010"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["Train class, used in order to perform the training process."],"metadata":{"id":"b8aqYyQUD8v_"}},{"cell_type":"code","source":["def main():\n","    parser = argparse.ArgumentParser()\n","    \n","    model_set = {'ResNet50': models.resnet50(pretrained=True), \n","                 'DenseNet169': models.densenet169(pretrained=True), \n","                 'VGG19': models.vgg19(pretrained=True),\n","                 'EfficientNet': torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0',\n","                                                pretrained=True)}\n","\n","    parser.add_argument(\"--model_to_test\",type=str,default='EfficientNet')\n","    parser.add_argument(\"--test\",type=bool,default=False)\n","    parser.add_argument(\"--lr\", type=float, default=1e-3)\n","    parser.add_argument(\"--batch_size\", type=int, default=64)\n","    parser.add_argument(\"--max_epochs\", type=int, default=30)\n","\n","    parser.add_argument(\"--ckpt_dir\", type=str, default=\"/content/gdrive/MyDrive/Progetto Quantum Binucci PhD/Checkpoint/VGG19\")\n","    parser.add_argument(\"--path_to_test\",type=str,default=\"/content/gdrive/MyDrive/Progetto Quantum Binucci PhD/Checkpoint/DenseNet169/landscape_16.pth\")\n","    parser.add_argument(\"--ckpt_name\", type=str, default=\"landscape\")\n","    parser.add_argument(\"--print_every\", type=int, default=1)\n","    parser.add_argument(\"--print_every_minibatches\", type=int, default=50)\n","\n","    # if you change image size, you must change all the network channels\n","    parser.add_argument(\"--image_size\", type=int, default=224)\n","    # parser.add_argument(\"--data_root\", type=str, default=\"/content/dataset\")\n","    parser.add_argument(\"--data_root\", type=str, default=\"/content/dataset\")\n","\n","\n","\n","\n","    args, unknown = parser.parse_known_args()\n","\n","    net = prepare_network_for_t_learning(model_set[args.model_to_test])\n","\n","    print(\"Test mode\" if args.test else \"Train Mode\")\n","\n","    solver = Solver(args,net=net)\n","    \n","    if args.test==False:\n","      pass\n","      #solver.fit()\n","    else:\n","      net.load_state_dict(torch.load(args.path_to_test))\n","      solver.load_network(net)\n","      accuracy = solver.test()\n","      print(f'Accuracy on the test-set for {net.__class__.__name__} = {accuracy*100}%')\n","      \n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"XPal7ereD9Cu","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a16237c0-9f9b-4fc1-bee8-d179fc180f06","executionInfo":{"status":"ok","timestamp":1676277136657,"user_tz":-60,"elapsed":3245,"user":{"displayName":"Francesco Binucci","userId":"08706289323156860079"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Using cache found in /root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"]},{"output_type":"stream","name":"stdout","text":["Number of parameters: 4015234\n","Train Mode\n","/content/dataset/seg_train\n","/content/dataset/seg_test\n","Current device: cuda\n","You requested the training of: EfficientNet\n"]}]}]}