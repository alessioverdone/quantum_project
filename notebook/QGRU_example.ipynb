{"cells":[{"cell_type":"markdown","metadata":{"id":"7ZSW_cjSW8-O"},"source":["### Import all the necessary libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"3pM0L6r-Wz-Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675410997612,"user_tz":-60,"elapsed":26342,"user":{"displayName":"Francesco Binucci","userId":"05312945905953918333"}},"outputId":"1e6a0fc0-95f3-4fc8-daba-08ba93c01216"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pennylane\n","  Downloading PennyLane-0.28.0-py3-none-any.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from pennylane) (0.10.2)\n","Requirement already satisfied: cachetools in /usr/local/lib/python3.8/dist-packages (from pennylane) (5.3.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from pennylane) (1.7.3)\n","Collecting pennylane-lightning>=0.28\n","  Downloading PennyLane_Lightning-0.28.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: appdirs in /usr/local/lib/python3.8/dist-packages (from pennylane) (1.4.4)\n","Collecting semantic-version>=2.7\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from pennylane) (2.25.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from pennylane) (3.0)\n","Requirement already satisfied: numpy<1.24 in /usr/local/lib/python3.8/dist-packages (from pennylane) (1.21.6)\n","Collecting retworkx\n","  Downloading retworkx-0.12.1-py3-none-any.whl (10 kB)\n","Collecting autoray>=0.3.1\n","  Downloading autoray-0.6.0-py3-none-any.whl (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.4/46.4 KB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: autograd in /usr/local/lib/python3.8/dist-packages (from pennylane) (1.5)\n","Collecting ninja\n","  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 KB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.8/dist-packages (from autograd->pennylane) (0.16.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->pennylane) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->pennylane) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->pennylane) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->pennylane) (2022.12.7)\n","Collecting rustworkx==0.12.1\n","  Downloading rustworkx-0.12.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: ninja, semantic-version, rustworkx, autoray, retworkx, pennylane-lightning, pennylane\n","Successfully installed autoray-0.6.0 ninja-1.11.1 pennylane-0.28.0 pennylane-lightning-0.28.2 retworkx-0.12.1 rustworkx-0.12.1 semantic-version-2.10.0\n"]}],"source":["###### comment these lines if you execute code in local\n","try:\n","  import pennylane as qml\n","except ModuleNotFoundError:\n","  !pip install pennylane\n","  import pennylane as qml\n","######\n","\n","import pennylane as qml\n","from pennylane import numpy as np\n","from pennylane.templates.embeddings import AngleEmbedding\n","from pennylane.templates.layers import StronglyEntanglingLayers\n","from pennylane.optimize import GradientDescentOptimizer\n","import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","# %matplotlib inline\n","import torch\n","from torch.autograd import Function, Variable\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","from sklearn.impute import SimpleImputer\n","import random\n","import math\n","\n","\n","np.random.seed = 7\n","torch.manual_seed(7)\n","random.seed(7)"]},{"cell_type":"markdown","metadata":{"id":"31TBbijOXCGZ"},"source":["### Data generation and processing"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"iEw7FrBlXC5B","colab":{"base_uri":"https://localhost:8080/","height":449},"executionInfo":{"status":"error","timestamp":1675411012764,"user_tz":-60,"elapsed":633,"user":{"displayName":"Francesco Binucci","userId":"05312945905953918333"}},"outputId":"a3887f48-1092-477a-b045-4769ee7c6dd0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Data of Solar Radiation on specific points of Earth's surface\n","Each row is a point, each column is a value of solar radiation in time, sampled each 30 min for a month\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-aca84a2c42e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data of Solar Radiation on specific points of Earth\\'s surface\\nEach row is a point, each column is a value of solar radiation in time, sampled each 30 min for a month'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'shape of data: {data.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data.csv'"]}],"source":["print('Data of Solar Radiation on specific points of Earth\\'s surface\\nEach row is a point, each column is a value of solar radiation in time, sampled each 30 min for a month')\n","\n","data = pd.read_csv('data.csv').iloc[0].values\n","print(f'shape of data: {data.shape}')\n","\n","print('\\nFor simplicity, take only the first 8 days\\n')\n","data = data[:8*24*2]\n","print(f'shape of data: {data.shape}')\n","\n","print(f'number of missing data: {len(data[data!=data])}')\n","print(f'index of missing data: {np.asarray(data!=data).nonzero()}')\n","\n","plt.plot(data)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vBmyUJACfEl8"},"outputs":[],"source":["def handle_missing_data(dataset,i):\n","    if i == 0:\n","        res = dataset[i+48]\n","    elif i== len(dataset)-1:\n","        res = dataset[i-48]\n","    else:\n","        res = (dataset[i-1]+dataset[i+1])/2\n","    return res\n","\n","for i in range(len(data)):\n","    if data[i]!=data[i]:\n","        data[i] = handle_missing_data(data,i)\n","\n","plt.plot(data)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WJR3CKr1fEl9"},"outputs":[],"source":["len_train = 0.8\n","window_size = 5\n","prediction_distance = 1\n","train = data[:int(len_train*len(data))].reshape(-1,1)\n","test = data[int(len_train*len(data))-window_size:].reshape(-1,1)\n","\n","scaler = MinMaxScaler(feature_range=(-1,1))\n","scaler.fit(train)\n","train = scaler.transform(train)\n","test = scaler.transform(test)\n","\n","def split_sequence(sequence, n_steps, prediction_distance):\n","    X, y = list(), list()\n","    for i in range(len(sequence)):\n","        # find the end of this pattern\n","        end_ix = i + n_steps\n","        # check if we are beyond the sequence\n","        if end_ix + prediction_distance-1> len(sequence)-1:\n","            break\n","        # gather input and output parts of the pattern\n","        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix+prediction_distance-1]\n","        X.append(seq_x)\n","        y.append(seq_y)\n","    return np.array(X), np.array(y)\n","\n","trainX, trainY = split_sequence(train, window_size ,prediction_distance)\n","testX, testY = split_sequence(test, window_size, prediction_distance)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wXt4OmPJ0_Mr"},"outputs":[],"source":["plt.plot(train)\n","plt.title('Train')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gjlFozVFfEl_"},"outputs":[],"source":["plt.plot(test)\n","plt.title('Test')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Puq1iF7XEpJ"},"outputs":[],"source":["\n","trainX = Variable(torch.Tensor(np.array(trainX))).view(-1,window_size,1)\n","trainY = Variable(torch.Tensor(np.array(trainY))).view(-1,1,1)\n","\n","testX = Variable(torch.Tensor(np.array(testX))).view(-1,window_size,1)\n","testY = Variable(torch.Tensor(np.array(testY))).view(-1,1,1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Slp1DU2xT9O8"},"outputs":[],"source":["from torch.utils.data import Dataset\n","class TimeseriesDataset(Dataset):   \n","    def __init__(self, X, y):\n","        self.X = X\n","        self.y = y\n","\n","    def __len__(self):\n","        return self.X.shape[0]\n","\n","    def __getitem__(self, index):\n","        return [self.X[index,:,:], self.y[index,:]]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dKWwBHBSHEe-"},"outputs":[],"source":["train_dataset = TimeseriesDataset(trainX, trainY)\n","test_dataset = TimeseriesDataset(testX, testY)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dhm8tPwk3Ojh"},"outputs":[],"source":["batch_size = 8 #len(train_dataset)\n","\n","train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = False)\n","test_loader = DataLoader(dataset = test_dataset, batch_size = len(test_dataset))"]},{"cell_type":"markdown","metadata":{"id":"pEKddQdEqDgJ"},"source":["### QGRU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZlRb2tG8XK9R"},"outputs":[],"source":["class QGRU(nn.Module):\n","    def __init__(self, \n","                input_size=1, \n","                hidden_size=3, \n","                n_qubits=4,\n","                n_qlayers=2,\n","                batch_first=True,\n","                return_sequences=False, \n","                return_state=False,\n","                backend=\"lightning.qubit\"):\n","        super(QGRU, self).__init__()\n","        self.n_inputs = input_size\n","        self.hidden_size = hidden_size\n","        self.concat_size = self.n_inputs + self.hidden_size\n","        self.n_qubits = n_qubits\n","        self.n_qlayers = n_qlayers\n","        self.backend = backend  # \"default.qubit\", \"qiskit.basicaer\", \"qiskit.ibm\"\n","        self.fc1 = nn.Linear(self.hidden_size, 1)\n","\n","        self.batch_first = batch_first\n","        self.return_sequences = return_sequences\n","        self.return_state = return_state\n","\n","        self.wires_reset = [f\"wire_reset_{i}\" for i in range(self.n_qubits)]\n","        self.wires_update = [f\"wire_update_{i}\" for i in range(self.n_qubits)]\n","        self.wires_output = [f\"wire_output_{i}\" for i in range(self.n_qubits)]\n","\n","        self.dev_reset = qml.device(self.backend, wires=self.wires_reset)\n","        self.dev_update = qml.device(self.backend, wires=self.wires_update)\n","        self.dev_output = qml.device(self.backend, wires=self.wires_output)\n","\n","        def _circuit_reset(inputs, weights):\n","            qml.templates.AngleEmbedding(inputs, wires=self.wires_reset)\n","            qml.templates.BasicEntanglerLayers(weights, wires=self.wires_reset)\n","            return [qml.expval(qml.PauliZ(wires=w)) for w in self.wires_reset]\n","        self.qlayer_reset = qml.QNode(_circuit_reset, self.dev_reset, interface=\"torch\", diff_method=\"adjoint\")\n","\n","        def _circuit_update(inputs, weights):\n","            qml.templates.AngleEmbedding(inputs, wires=self.wires_update)\n","            qml.templates.BasicEntanglerLayers(weights, wires=self.wires_update)\n","            return [qml.expval(qml.PauliZ(wires=w)) for w in self.wires_update]\n","        self.qlayer_update = qml.QNode(_circuit_update, self.dev_update, interface=\"torch\", diff_method=\"adjoint\")\n","\n","        def _circuit_output(inputs, weights):\n","            qml.templates.AngleEmbedding(inputs, wires=self.wires_output)\n","            qml.templates.BasicEntanglerLayers(weights, wires=self.wires_output)\n","            return [qml.expval(qml.PauliZ(wires=w)) for w in self.wires_output]\n","        self.qlayer_output = qml.QNode(_circuit_output, self.dev_output, interface=\"torch\", diff_method=\"adjoint\")\n","\n","        weight_shapes = {\"weights\": (n_qlayers, n_qubits)}\n","        print(f\"weight_shapes (n_qlayers, n_qubits) = ({n_qlayers}, {n_qubits})\")\n","\n","        #Define QGRU layers\n","        self.clayer_in = nn.Linear(self.concat_size, n_qubits)\n","\n","        self.vqc_reset =  qml.qnn.TorchLayer(self.qlayer_reset, weight_shapes)\n","        self.vqc_update =  qml.qnn.TorchLayer(self.qlayer_update, weight_shapes)\n","        self.vqc_output =  qml.qnn.TorchLayer(self.qlayer_output, weight_shapes)\n","\n","        self.clayer_out = nn.Linear(self.n_qubits, self.hidden_size)\n","\n","    def forward(self, x, init_states=None):\n","\n","        if self.batch_first is True:\n","            batch_size, seq_length, features_size = x.size()\n","        else:\n","            seq_length, batch_size, features_size = x.size()\n","\n","        hidden_seq = []\n","        if init_states is None:\n","            h_t = torch.zeros(batch_size, self.hidden_size)  # hidden state (output)\n","        else:\n","            # for now we ignore the fact that in PyTorch you can stack multiple RNNs\n","            # so we take only the first elements of the init_states tuple init_states[0][0], init_states[1][0]\n","            h_t = init_states\n","            h_t = h_t[0]\n","\n","        for t in range(seq_length):\n","            # get features from the t-th element in seq, for all entries in the batch\n","            x_t = x[:, t, :]\n","\n","            # Concatenate input and hidden state\n","            v_t = torch.cat((h_t, x_t), dim=1)\n","\n","            # match qubit dimension\n","            y_t = self.clayer_in(v_t)\n","\n","            r_t = torch.sigmoid(self.clayer_out(self.vqc_reset(y_t)))  # forget block\n","            z_t = torch.sigmoid(self.clayer_out(self.vqc_update(y_t)))  # update block\n","\n","            # Concatenate input and hidden state\n","            v2_t = torch.cat(((r_t * h_t), x_t), dim=1)\n","\n","            # match qubit dimension\n","            y2_t = self.clayer_in(v2_t)\n","            \n","            h_tilde_t = torch.tanh(self.clayer_out(self.vqc_output(y2_t)))\n","\n","            h_t = ((1-z_t) * h_tilde_t) + (z_t * h_t)\n","\n","            hidden_seq.append(h_t.unsqueeze(0))\n","        hidden_seq = torch.cat(hidden_seq, dim=0)\n","        hidden_seq = hidden_seq.transpose(0, 1).contiguous()\n","        x = self.fc1(h_t)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"kzvBtAcFfEmD"},"source":["### LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Es0q9fzsfEmE"},"outputs":[],"source":["class LSTM(nn.Module):\n","    def __init__(self):\n","        super(LSTM, self).__init__()\n","        self.hidden1 = 5\n","        self.lstm = nn.LSTM(1,self.hidden1,1,batch_first=True)\n","        self.fc1 = nn.Linear(self.hidden1, 1)\n","            \n","    def forward(self, x):        \n","        _, (x,_) = self.lstm(x)\n","        x = x.view(-1, self.hidden1)\n","        x = self.fc1(x)\n","        return x\n","    \n","    \n","    def predict(self, x):\n","        pred = self.forward(x)\n","        return torch.tensor(pred)"]},{"cell_type":"markdown","metadata":{"id":"Yix2c70u2xtq"},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ll2cg42rXa4w"},"outputs":[],"source":["runs=1\n","\n","# number of epochs to train the model\n","epochs = 100\n","\n","# arrays to save evaluation results\n","final_MSE = np.zeros((epochs,runs))\n","final_MAE = np.zeros((epochs,runs))\n","\n","for i in range(0,runs):\n","    print('Run:',i)\n","    rng=np.random.default_rng(i)\n","    torch.manual_seed(i)\n","    random.seed(i)\n","    \n","    network = QGRU()\n","    \n","    # specify optimizer (RMSprop) and learning rate\n","    optimizer = optim.RMSprop(network.parameters(), lr=0.01)\n","    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=95, gamma=0.7) \n","\n","    # specify loss function (Mean Squared Error)\n","    loss_func = nn.MSELoss()\n","    \n","    epoch_train_losses = []\n","    epoch_test_losses = []\n","    for epoch in range(0,epochs):\n","\n","      # monitor training loss\n","      train_loss = 0.0\n","      test_loss = 0.0\n","\n","      ###################\n","      # train the model #\n","      ###################\n","      network.train() # prep model for training\n","      for batch_idx, (x,y) in enumerate(train_loader):\n","        # clear the gradients of all optimized variables\n","        optimizer.zero_grad(set_to_none=True)   \n","        # forward pass: compute predicted outputs by passing inputs to the model\n","        output = network(x).reshape(-1,1)\n","        # calculate the loss (MSELoss automatically computes the mean of the sum of the batch losses)\n","        loss = (loss_func(output, y.view(-1,1)))\n","        # backward pass: compute gradient of the loss with respect to model parameters\n","        loss.backward()\n","        # perform a single optimization step (parameter update)\n","        optimizer.step()\n","        # update running training loss\n","        train_loss += loss.item()*x.size(0)\n","\n","        if batch_idx%10 == 0:\n","            print('\\rEpoch %d ~ Batch %d (of %d) ~ Loss %f ' % (epoch, batch_idx, len(train_loader)-1, loss.item()), end='\\n')\n","  \n","      ######################    \n","      # validate the model #\n","      ######################\n","      network.eval() # prep model for evaluation\n","      with torch.no_grad():\n","        for x,y in test_loader:\n","          # forward pass: compute predicted outputs by passing inputs to the model\n","          output = network(x).reshape(-1,1)\n","\n","          # calculate the loss\n","          loss = (loss_func(output, y.view(-1,1)))\n","          # update running validation loss \n","          test_loss += loss.item()*x.size(0)\n","\n","      # print training/validation statistics \n","      # calculate average loss over an epoch\n","      train_loss = train_loss/len(train_loader.sampler)\n","      test_loss = test_loss/len(test_loader.sampler)\n","      epoch_train_losses.append(train_loss)\n","      epoch_test_losses.append(test_loss)\n","\n","      print('\\nEpoch %d ~ Loss Training %f ~ Loss Test %f' % (epoch, np.mean(train_loss), np.mean(test_loss)), end='\\n\\n')\n","      scheduler.step()\n","\n","      predictions = network(testX).reshape(-1,1).cpu().detach().numpy()\n","      testScore = (mean_squared_error(scaler.inverse_transform(testY.view(-1,1)), scaler.inverse_transform(predictions)))\n","      final_MSE[epoch,i] = testScore\n","      if epoch % 5 == 4:\n","        print('Test Score: %.5f MSE' % (testScore))\n","        print('epoch:',epoch)\n","\n","      testScore_MAE = mean_absolute_error(scaler.inverse_transform(testY.view(-1,1)), scaler.inverse_transform(predictions))\n","      final_MAE[epoch,i] = testScore_MAE\n","\n","    print('Test Score: %.5f MSE' % (testScore))\n","    print('Test Score: %.5f MAE\\n' % (testScore_MAE))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JU_1EKHafEmH"},"outputs":[],"source":["print('Test Score: %.5f MSE' % (testScore))\n","print('Test Score: %.5f MAE\\n' % (testScore_MAE))"]},{"cell_type":"markdown","metadata":{"id":"gryZSGeNxmYZ"},"source":["# Errors and Plots"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8plZPA4wXgpB"},"outputs":[],"source":["plt.plot(epoch_train_losses)\n","plt.plot(epoch_test_losses)\n","plt.title('NN Training Convergence for {} epochs'.format(epochs))\n","plt.xlabel('Epochs')\n","plt.ylabel('MSE Loss')\n","plt.legend(['Training', 'Test'])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rzDbPpcc4_NR"},"outputs":[],"source":["predictions = scaler.inverse_transform(np.reshape(predictions,(-1,1)))\n","testY = scaler.inverse_transform(testY.view(-1,1))\n","plt.plot(predictions)\n","plt.plot(testY)\n","plt.title('NN Test Predictions vs Ground Truth')\n","plt.xlabel('x')\n","plt.ylabel('Surface Solar Radiation (W/m^2)')\n","plt.legend(['Predictions', 'Ground truth'])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pFsWpQt1fEmJ"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["pEKddQdEqDgJ","kzvBtAcFfEmD"]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}